<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Santander Customer Satisfaction - Random Forest Classifier | Derek Elliott Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="This is the second in a series of post detailing the analysis I’ve performed on the Santander Customer Satisfaction competition on Kaggle.
This is the first algorithm that I tried to tune the paramete">
<meta property="og:type" content="article">
<meta property="og:title" content="Santander Customer Satisfaction - Random Forest Classifier">
<meta property="og:url" content="http://derekelliott.me/2016/12/03/Santander-Customer-Satisfaction-Random-Forest-Classifier/index.html">
<meta property="og:site_name" content="Derek Elliott Blog">
<meta property="og:description" content="This is the second in a series of post detailing the analysis I’ve performed on the Santander Customer Satisfaction competition on Kaggle.
This is the first algorithm that I tried to tune the paramete">
<meta property="og:updated_time" content="2016-12-04T03:05:28.805Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Santander Customer Satisfaction - Random Forest Classifier">
<meta name="twitter:description" content="This is the second in a series of post detailing the analysis I’ve performed on the Santander Customer Satisfaction competition on Kaggle.
This is the first algorithm that I tried to tune the paramete">
  
    <link rel="alternate" href="/atom.xml" title="Derek Elliott Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  

</head>

<body>
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Derek Elliott Blog</h1>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          <article id="post-Santander-Customer-Satisfaction-Random-Forest-Classifier" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      Santander Customer Satisfaction - Random Forest Classifier
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2016/12/03/Santander-Customer-Satisfaction-Random-Forest-Classifier/" class="article-date"><time datetime="2016-12-04T02:43:30.000Z" itemprop="datePublished">2016-12-03</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>This is the second in a series of post detailing the analysis I’ve performed on the <a href="https://www.kaggle.com/c/santander-customer-satisfaction" target="_blank" rel="external">Santander Customer Satisfaction</a> competition on Kaggle.</p>
<p>This is the first algorithm that I tried to tune the parameters on my own.  I couldn’t find a good guide, so I did my best based on the guide I used for the gradient boosted algorithm.  I used the same helper function, modified slightly to fit the algorithm.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">modelFit</span><span class="params">(alg, dtrain, predictors, target, performCV = True, printFeatReport = True, cv_folds = <span class="number">5</span>)</span>:</span></div><div class="line"></div><div class="line">  alg.fit(dtrain[predictors], dtrain[target])</div><div class="line"></div><div class="line">  dtrain_predictions = alg.predict(dtrain[predictors])</div><div class="line">  dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,<span class="number">1</span>]</div><div class="line"></div><div class="line">  <span class="keyword">if</span> performCV:</div><div class="line">      cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain[target], \</div><div class="line">                                                 cv = cv_folds, scoring = <span class="string">'roc_auc'</span> )</div><div class="line"></div><div class="line">  print(<span class="string">'\nModel Report'</span>)</div><div class="line">  print(<span class="string">'Accuracy : &#123;:.4g&#125;'</span>.format(metrics.accuracy_score(dtrain[target].values, dtrain_predictions)))</div><div class="line">  print(<span class="string">'AUC Score (Train): &#123;:f&#125;'</span>.format(metrics.roc_auc_score(dtrain[target], dtrain_predprob)))</div><div class="line"></div><div class="line">  <span class="keyword">if</span> performCV:</div><div class="line">      print(<span class="string">'CV Score: Mean - &#123;:.7g&#125; | Std - &#123;:.7g&#125; | Min - &#123;:.7g&#125; | Max - &#123;:.7g&#125;'</span>.format(np.mean(cv_score),\</div><div class="line">                                                                                          np.std(cv_score),\</div><div class="line">                                                                                          np.min(cv_score),\</div><div class="line">                                                                                          np.max(cv_score)))</div><div class="line"></div><div class="line">  <span class="keyword">if</span> printFeatReport:</div><div class="line">      feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending = <span class="keyword">False</span>)</div><div class="line">      feat_imp.plot(kind = <span class="string">'bar'</span>, title = <span class="string">'Feature Importances'</span>)</div><div class="line">      plt.ylabel(<span class="string">'Feature Importance Score'</span>)</div></pre></td></tr></table></figure>
<p>Along with what I mentioned last time, I think I want to modify this to automatically remove features that don’t contribute to the model.  I could do it iteratively and stop when the cross validation score starts to drop.  These models already take a few minutes each to run, and when I start to cross validate, it could take 10 or 15 minutes to train.  In the grand scheme of things, that’s not that long considering what it could take with more advanced models, but if I start trying to ensemble I’d rather not have to wait overnight to check my results.  </p>
<p>I use the exact same code to import and clean the data to get it ready for training the model, but I’ll include it below for the sake of completeness.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'Data/Santander/train.csv'</span>)</div><div class="line">test = pd.read_csv(<span class="string">'Data/Santander/test.csv'</span>)</div><div class="line"></div><div class="line">dropCols = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train.columns.values:</div><div class="line">    <span class="keyword">if</span> len(train[i].unique()) == <span class="number">1</span>:</div><div class="line">        dropCols.append(i)</div><div class="line">print(<span class="string">'Dropping &#123;&#125; columns due to non-unique entries'</span>.format(len(dropCols)))</div><div class="line">train.drop(dropCols, axis = <span class="number">1</span>,  inplace = <span class="keyword">True</span>)</div><div class="line">test.drop(dropCols, axis = <span class="number">1</span>, inplace = <span class="keyword">True</span>)</div><div class="line"></div><div class="line">dropCols = []</div><div class="line">c = train.columns</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(c)<span class="number">-1</span>):</div><div class="line">    v = train[c[i]].values</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,len(c)):</div><div class="line">        <span class="keyword">if</span> np.array_equal(v,train[c[j]].values):</div><div class="line">            dropCols.append(c[j])</div><div class="line">print(<span class="string">'Dropping &#123;&#125; columns due to duplicate columns'</span>.format(len(dropCols)))</div><div class="line">train.drop(dropCols, axis = <span class="number">1</span>,  inplace = <span class="keyword">True</span>)</div><div class="line">test.drop(dropCols, axis = <span class="number">1</span>, inplace = <span class="keyword">True</span>)</div><div class="line"></div><div class="line">train.loc[train.var3 &lt; <span class="number">-10000</span>, <span class="string">'var3'</span>] = np.nan</div><div class="line">test.loc[test.var3 &lt; <span class="number">-10000</span>, <span class="string">'var3'</span>] = np.nan</div><div class="line"></div><div class="line">colsWithNAN = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train.columns.values:</div><div class="line">    <span class="keyword">if</span> train[i].isnull().sum() &gt; <span class="number">0</span>:</div><div class="line">        colsWithNAN.append(i)</div><div class="line">train.drop(colsWithNAN, axis = <span class="number">1</span>,  inplace = <span class="keyword">True</span>)</div><div class="line">test.drop(colsWithNAN, axis = <span class="number">1</span>, inplace = <span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>I ran the model with the default parameter values and set the random state so that I could train multiple times and get consistent results.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">pred = [i <span class="keyword">for</span> i <span class="keyword">in</span> train.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'ID'</span>, <span class="string">'TARGET'</span>]]</div><div class="line">rfc0 = RandomForestClassifier(n_estimators = <span class="number">500</span>, \</div><div class="line">                              random_state = <span class="number">42</span>)</div><div class="line">modelFit(rfc0, train, pred, <span class="string">'TARGET'</span>)</div></pre></td></tr></table></figure>
<p>The default parameters resulted in a CV score of 0.7653.  Not bad for a first run, but there is a lot of room for improvement.</p>
<p>Next, instead of running several different grid searches on each parameter, I ran a randomized search on all of the relevant parameters.  The function to report the findings of the random search was taken from the <a href="http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html" target="_blank" rel="external">scikit-learn</a> example.  It was modified very slightly to fit my needs though.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">report</span><span class="params">(grid_scores, n_top=<span class="number">3</span>)</span>:</span></div><div class="line">    top_scores = sorted(grid_scores, key=itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)[:n_top]</div><div class="line">    <span class="keyword">for</span> i, score <span class="keyword">in</span> enumerate(top_scores):</div><div class="line">        print(<span class="string">"\nModel with rank: &#123;0&#125;"</span>.format(i + <span class="number">1</span>))</div><div class="line">        print(<span class="string">"Mean validation score: &#123;0:.3f&#125; (std: &#123;1:.3f&#125;)"</span>.format(score.mean_validation_score,np.std(score.cv_validation_scores)))</div><div class="line">        print(<span class="string">"Parameters: &#123;0&#125;"</span>.format(score.parameters))</div><div class="line"></div><div class="line"></div><div class="line">param_dist = &#123;<span class="string">"max_depth"</span>: sp_randint(<span class="number">3</span>,<span class="number">10</span>),</div><div class="line">              <span class="string">"max_features"</span>: sp_randint(<span class="number">15</span>, <span class="number">29</span>),</div><div class="line">              <span class="string">"min_samples_split"</span>: sp_randint(<span class="number">400</span>, <span class="number">600</span>),</div><div class="line">              <span class="string">"min_samples_leaf"</span>: sp_randint(<span class="number">40</span>, <span class="number">60</span>),</div><div class="line">              <span class="string">"bootstrap"</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>],</div><div class="line">              <span class="string">"criterion"</span>: [<span class="string">"gini"</span>, <span class="string">"entropy"</span>]&#125;</div><div class="line"></div><div class="line">random_search = RandomizedSearchCV(rfc0, param_distributions = param_dist, n_iter = <span class="number">20</span>)</div><div class="line">random_search.fit(train[pred], train[<span class="string">'TARGET'</span>])</div></pre></td></tr></table></figure>
<p>After running it, it produced the following output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Model <span class="keyword">with</span> rank: <span class="number">1</span></div><div class="line">Mean validation score: <span class="number">0.960</span> (std: <span class="number">0.000</span>)</div><div class="line">Parameters: &#123;<span class="string">'bootstrap'</span>: <span class="keyword">True</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">45</span>, <span class="string">'min_samples_split'</span>: <span class="number">404</span>, <span class="string">'criterion'</span>: <span class="string">'gini'</span>, <span class="string">'max_features'</span>: <span class="number">24</span>, <span class="string">'max_depth'</span>: <span class="number">8</span>&#125;</div><div class="line"></div><div class="line">Model <span class="keyword">with</span> rank: <span class="number">2</span></div><div class="line">Mean validation score: <span class="number">0.960</span> (std: <span class="number">0.000</span>)</div><div class="line">Parameters: &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">45</span>, <span class="string">'min_samples_split'</span>: <span class="number">554</span>, <span class="string">'criterion'</span>: <span class="string">'gini'</span>, <span class="string">'max_features'</span>: <span class="number">24</span>, <span class="string">'max_depth'</span>: <span class="number">6</span>&#125;</div><div class="line"></div><div class="line">Model <span class="keyword">with</span> rank: <span class="number">3</span></div><div class="line">Mean validation score: <span class="number">0.960</span> (std: <span class="number">0.000</span>)</div><div class="line">Parameters: &#123;<span class="string">'bootstrap'</span>: <span class="keyword">True</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">52</span>, <span class="string">'min_samples_split'</span>: <span class="number">597</span>, <span class="string">'criterion'</span>: <span class="string">'entropy'</span>, <span class="string">'max_features'</span>: <span class="number">28</span>, <span class="string">'max_depth'</span>: <span class="number">4</span>&#125;</div><div class="line">report(random_search.grid_scores_)</div></pre></td></tr></table></figure>
<p>Then, I created a model with the best parameters and trained it to check out the cross validation score.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">rfc1 = RandomForestClassifier(n_estimators = <span class="number">500</span>, \</div><div class="line">                              max_depth = <span class="number">8</span>, \</div><div class="line">                              max_features = <span class="number">24</span>, \</div><div class="line">                              min_samples_split = <span class="number">404</span>, \</div><div class="line">                              min_samples_leaf = <span class="number">45</span>, \</div><div class="line">                              bootstrap = <span class="keyword">True</span>, \</div><div class="line">                              random_state = <span class="number">42</span>)</div><div class="line">modelFit(rfc1, train, pred, <span class="string">'TARGET'</span>)</div></pre></td></tr></table></figure>
<p>This lead to a CV score of 0.8143.  That’s an increase of almost 0.05.  That’s a substantial improvement over the default parameters.  This is as far as I took this model, but in the future, I plan on following up with a few grid searches to further refine the parameters.  This is because of the way the RandomizedSearchCV searches for the best parameters.  It only selects a sample from the given range, so while what it found is an improvement, it might not have provided the optimal parameters.</p>
<p>That’s it for this edition.  The next post will detail how I used the XGBoost model to fit the same data.  That’s all I already have prepared, so following that, it’s hard to say what will be coming.  I might go back and do the things I’ve already suggested with the models I already have, or I’ll start to ensemble.  I also need to put up something on the initial data exploration and do some visualizations.  So, stay tuned.  You can find the <a href="https://github.com/SayWhat1/Santander-Customer-Satisfaction-Kaggle/blob/master/Santander%20Customer%20Satisfaction%20RandomForest.ipynb" target="_blank" rel="external">notebook</a> on my GitHub, but as I work on this model and the others, it’s subject to change.</p>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://derekelliott.me/2016/12/03/Santander-Customer-Satisfaction-Random-Forest-Classifier/" data-id="ciwa1s0yq0001awk7ync98yl5" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python-Data-Analysis-Kaggle/">Python, Data Analysis, Kaggle</a></li></ul>


    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="/2016/12/03/Santander-Customer-Satisfaction-Gradient-Boosted-Classifier/" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">Santander Customer Satisfaction - Gradient Boosted Classifier</span>
    </a>
  </li>
  
  
</ul>


  
</article>




        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p>Data Scientist and cloud analytics developer at Booz Allen Hamilton.</p>

</div>


  


  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Python-Data-Analysis-Kaggle/">Python, Data Analysis, Kaggle</a><span class="sidebar-module-list-count">2</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/Python-Data-Analysis-Kaggle/" style="font-size: 10px;">Python, Data Analysis, Kaggle</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/12/">December 2016</a><span class="sidebar-module-list-count">3</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2016/12/03/Santander-Customer-Satisfaction-Random-Forest-Classifier/">Santander Customer Satisfaction - Random Forest Classifier</a>
        </li>
      
        <li>
          <a href="/2016/12/03/Santander-Customer-Satisfaction-Gradient-Boosted-Classifier/">Santander Customer Satisfaction - Gradient Boosted Classifier</a>
        </li>
      
        <li>
          <a href="/2016/12/03/First-Post/">This is just a test</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2016 Derek Elliott<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>

</body>
</html>
